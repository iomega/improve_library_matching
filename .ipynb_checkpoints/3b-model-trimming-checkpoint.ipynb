{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "\n",
    "ROOT = os.path.dirname(os.getcwd())\n",
    "#path_data = os.path.join(ROOT, 'data')\n",
    "path_data = 'C:\\\\Users\\\\joris\\\\Documents\\\\eScience_data\\\\data'\n",
    "sys.path.insert(0, ROOT)\n",
    "sys.path.insert(0, \"C:\\\\Users\\\\joris\\\\Documents\\\\eScience_data\\\\spec2vec_gnps_data_analysis\\\\custom_functions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading processed query, library and found_matches data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joris\\Documents\\eScience_data\\data\\training_query_library_s2v_2dec.pickle\n"
     ]
    }
   ],
   "source": [
    "# load training dataset, for making these see notebook 1b\n",
    "\n",
    "outfile = os.path.join(path_data, 'training_query_library_s2v_2dec.pickle')\n",
    "print(outfile)\n",
    "if os.path.exists(outfile):\n",
    "    with open(outfile, 'rb') as inf:\n",
    "        training_query_library_s2v_2dec = pickle.load(inf)\n",
    "        old_and_unique_documents_query_s2v_2dec, old_and_unique_documents_library_s2v_2dec = training_query_library_s2v_2dec\n",
    "else:\n",
    "    with open(outfile, 'wb') as outf:\n",
    "        training_query_library_s2v_2dec = (old_and_unique_documents_query_s2v_2dec, old_and_unique_documents_library_s2v_2dec)\n",
    "        pickle.dump(training_query_library_s2v_2dec, outf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joris\\Documents\\eScience_data\\data\\testing_query_library_s2v_2dec.pickle\n"
     ]
    }
   ],
   "source": [
    "#loading test dataset\n",
    "\n",
    "outfile = os.path.join(path_data, 'testing_query_library_s2v_2dec.pickle')\n",
    "print(outfile)\n",
    "if os.path.exists(outfile):\n",
    "    with open(outfile, 'rb') as inf:\n",
    "        testing_query_library_s2v_2dec = pickle.load(inf)\n",
    "        new_and_unique2_documents_query_s2v_2dec, new_and_unique2_documents_library_s2v_2dec = testing_query_library_s2v_2dec\n",
    "else:\n",
    "    with open(outfile, 'wb') as outf:\n",
    "        testing_query_library_s2v_2dec = (new_and_unique2_documents_query_s2v_2dec, new_and_unique2_documents_library_s2v_2dec)\n",
    "        pickle.dump(testing_query_library_s2v_2dec, outf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joris\\Documents\\eScience_data\\data\\old_and_unique_found_matches_s2v_2dec.pickle\n",
      "C:\\Users\\joris\\Documents\\eScience_data\\data\\new_and_unique2_found_matches_s2v_2dec.pickle\n"
     ]
    }
   ],
   "source": [
    "# load/make found_matches for both query and test set\n",
    "\n",
    "# define models\n",
    "path_models = os.path.join(path_data, \"trained_models\")\n",
    "model_file2 = os.path.join(path_models, \"spec2vec_library_testing_4000removed_2dec.model\")\n",
    "\n",
    "# check if output exists, if not: query models\n",
    "outfile = os.path.join(path_data, 'old_and_unique_found_matches_s2v_2dec.pickle')\n",
    "print(outfile)\n",
    "if os.path.exists(outfile):\n",
    "    with open(outfile, 'rb') as inf:\n",
    "        old_and_unique_found_matches_s2v_2dec = pickle.load(inf)\n",
    "else:\n",
    "    # load model\n",
    "    model2 = gensim.models.Word2Vec.load(model_file2)\n",
    "    print(model2)\n",
    "    old_and_unique_found_matches_s2v_2dec = library_matching(old_and_unique_documents_query_s2v_2dec,\n",
    "                                                             old_and_unique_documents_library_s2v_2dec,\n",
    "                                                             model2,\n",
    "                                                             presearch_based_on=[\"spec2vec-top200\"],\n",
    "                                                             ignore_non_annotated=True,\n",
    "                                                             intensity_weighting_power=0.5,\n",
    "                                                             allowed_missing_percentage=100,\n",
    "                                                             cosine_tol=0.005,\n",
    "                                                             mass_tolerance=1.0)\n",
    "    with open(outfile, 'wb') as outf:\n",
    "        pickle.dump(old_and_unique_found_matches_s2v_2dec, outf)\n",
    "\n",
    "outfile = os.path.join(path_data, 'new_and_unique2_found_matches_s2v_2dec.pickle')\n",
    "print(outfile)\n",
    "if os.path.exists(outfile):\n",
    "    with open(outfile, 'rb') as inf:\n",
    "        new_and_unique2_found_matches_s2v_2dec = pickle.load(inf)\n",
    "else:\n",
    "    # load model\n",
    "    model2 = gensim.models.Word2Vec.load(model_file2)\n",
    "    print(model2)\n",
    "    new_and_unique2_found_matches_s2v_2dec = library_matching(new_and_unique2_documents_query_s2v_2dec,\n",
    "                                                             new_and_unique2_documents_library_s2v_2dec,\n",
    "                                                             model2,\n",
    "                                                             presearch_based_on=[\"spec2vec-top200\"],\n",
    "                                                             ignore_non_annotated=True,\n",
    "                                                             intensity_weighting_power=0.5,\n",
    "                                                             allowed_missing_percentage=100,\n",
    "                                                             cosine_tol=0.005,\n",
    "                                                             mass_tolerance=1.0)\n",
    "    with open(outfile, 'wb') as outf:\n",
    "        pickle.dump(new_and_unique2_found_matches_s2v_2dec, outf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max parent mass: 13418.370894192036\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get max parent mass in dataset\n",
    "all_q_masses = [doc._obj.get(\"parent_mass\") for doc in old_and_unique_documents_query_s2v_2dec]\n",
    "all_l_masses = [doc._obj.get(\"parent_mass\") for doc in old_and_unique_documents_library_s2v_2dec]\n",
    "max_parent_mass = max(all_q_masses + all_l_masses)\n",
    "print(\"Max parent mass:\", max_parent_mass)\n",
    "plt.hist(all_q_masses + all_l_masses, bins = 200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem, DataStructs\n",
    "\n",
    "def find_info_matches(matches, documents_library, documents_query,\n",
    "                      add_label = True, add_tanimoto_sim = True, add_cols = False,\n",
    "                      add_num_matches_transform = True, add_mass_transform = True,\n",
    "                      max_parent_mass = False, add_mass_similarity = True):\n",
    "    '''\n",
    "    To each df in matches, add more info like tanimoto scores vs query etc.\n",
    "    \n",
    "    A matching inchikey gets label 1 and non-matching 0.\n",
    "\n",
    "    matches: list of pandas DataFrames, library matching result of query on library\n",
    "    documents_library: list of SpectrumDocuments, spectra in library\n",
    "    documents_query: list of SpectrumDocuments, spectra in query set.\n",
    "        Indices should correspond to indices of matches.\n",
    "    bins: list of int/float, the cutoff for the mass change, will result in boolean columns,\n",
    "        i.e. if a cutoff is 2 there will be a column with 1 (true) or 0 (false) for if the mass change\n",
    "        is within 2\n",
    "    calc_change: bool, instead of bins add a percentage change of the parent mass difference\n",
    "    add_label: bool, add a label for inchikey match or not\n",
    "    add_tanimoto_sim: bool, add tanimoto similarity or not\n",
    "    add_cols: bool/list of str, add other info present in metadata such as parent_mass, adduct\n",
    "        default: False\n",
    "    add_num_matches_transform: bool, transform cosine and mod_cosine matches to a number 0-1.\n",
    "        both matches are transformed to between 0-1 by doing 1-0.93^num_matches\n",
    "    add_mass_transform: bool, add transform of the parent masses to a fraction of the maximal parent mass\n",
    "    max_parent_mass: int/float, the maximum parent mass in the dataset, default = False\n",
    "    add_mass_similarity: bool, add similarity of parent mass to the query as a scaled number from 0-1\n",
    "        where The similarity in dalton is calculated and transformed into a value 0 - 1 by doing\n",
    "        1 - base_num^diff_in_dalton\n",
    "    \n",
    "    Output\n",
    "    matches_with_info: list of pandas DataFrames, library matching result of query\n",
    "        on library with matching labels\n",
    "    '''\n",
    "    matches_with_info = []\n",
    "    if add_mass_transform and not max_parent_mass:\n",
    "        print(\"If you want to transform the masses, please provide a max_parent_mass\")\n",
    "        return\n",
    "    else:\n",
    "        print('Max parent mass:', max_parent_mass)\n",
    "\n",
    "    for query_id in range(len(documents_query)):\n",
    "        match = matches[query_id].copy()\n",
    "        if add_label:\n",
    "            query_inchi = documents_query[query_id]._obj.get(\"inchikey\")[:14]\n",
    "            match = find_inchikey_match(match, documents_library, query_inchi)\n",
    "        if add_cols:\n",
    "            match = find_basic_info(match, documents_library, add_cols)\n",
    "        if add_tanimoto_sim:\n",
    "            query_smiles = documents_query[query_id]._obj.get(\"smiles\")\n",
    "            match = find_tanimoto_sim(match, documents_library, query_smiles)\n",
    "        if add_num_matches_transform:\n",
    "            match = transform_num_matches(match)\n",
    "        if add_mass_transform:\n",
    "            #add parent_mass if its not there already\n",
    "            match = find_basic_info(match, documents_library, add_cols = ['parent_mass'])\n",
    "            match['parent_mass'] = [cur_pm/max_parent_mass for cur_pm in match['parent_mass']]\n",
    "        if add_mass_similarity:\n",
    "            if 'mass_match' in match:\n",
    "                match.drop(['mass_match'], axis=1, inplace=True)\n",
    "            q_mass = documents_query[query_id]._obj.get(\"parent_mass\")\n",
    "            match = find_mass_similarity(match, documents_library, q_mass, base_num = 0.8)\n",
    "        \n",
    "        matches_with_info.append(match)\n",
    "    return matches_with_info\n",
    "\n",
    "def find_inchikey_match(matches, documents_library, query_inchi):\n",
    "    '''To each match in the matches df, add label for matching inchikey (1) or non-matching (0)\n",
    "\n",
    "    matches: pandas DataFrame, library matching result of 1 query on library\n",
    "    documents_library: list of SpectrumDocuments, spectra in library\n",
    "    query_inchi: str, first 14 symbols of query inchikey\n",
    "    df: pandas DataFrame, library matching result of query on library with matching labels\n",
    "    '''\n",
    "    matches_with_labels = []\n",
    "    df = matches.copy()\n",
    "    library_ids = df.index.values\n",
    "    labels = []\n",
    "    for lib_id in library_ids:\n",
    "        lib_inchi = documents_library[lib_id]._obj.get(\"inchikey\")[:14]\n",
    "        lab = 0\n",
    "        if query_inchi == lib_inchi:\n",
    "            lab = 1\n",
    "        labels.append(lab)\n",
    "    df['label'] = labels\n",
    "    return df\n",
    "\n",
    "def find_mass_matches(matches, documents_library, query_mass, bins = [2, 5], calc_change = False):\n",
    "    '''\n",
    "    To each match in matches df, add the mass change of query to match in bins or a percentage change\n",
    "\n",
    "    matches: pandas DataFrame, library matching result of 1 query on library\n",
    "    documents_library: list of SpectrumDocuments, spectra in library\n",
    "    query_mass: float, parent mass of query\n",
    "    bins: list of int/float, the cutoff for the mass change, will result in boolean columns,\n",
    "        i.e. if a cutoff is 2 there will be a column with 1 (true) or 0 (false) for if the mass change\n",
    "        is within 2\n",
    "    calc_change: bool, instead of bins add a percentage change of the parent mass difference\n",
    "    df: pandas DataFrame, library matching result of 1 query on library with mass matches\n",
    "    '''\n",
    "    range_bins = range(len(bins)) #calc once\n",
    "    df = matches.copy()\n",
    "    library_ids = df.index.values\n",
    "    masses = [[] for _ in range_bins] #initialise\n",
    "    mass_changes = []\n",
    "    for lib_id in library_ids:\n",
    "        lib_mass = documents_library[lib_id]._obj.get(\"parent_mass\")\n",
    "        if calc_change: #calculate a percentage change in parent mass instead of discrete bins\n",
    "            perc_change = abs(lib_mass - query_mass) / query_mass * 100\n",
    "            mass_changes.append(perc_change)\n",
    "        else:\n",
    "            for bin_i in range_bins:\n",
    "                cutoff = bins[bin_i]\n",
    "                lab = 0\n",
    "                if abs(query_mass - lib_mass) < cutoff:\n",
    "                    lab = 1\n",
    "                masses[bin_i].append(lab)\n",
    "    #add to df\n",
    "    if calc_change:\n",
    "        df['perc_mass_change'] = mass_changes\n",
    "    else:\n",
    "        for bin_i in range_bins:\n",
    "            df['mass_match_' + str(bins[bin_i])] = masses[bin_i]\n",
    "    return df\n",
    "\n",
    "def find_basic_info(matches, documents_library, add_cols = ['parent_mass']):\n",
    "    '''\n",
    "    To each match in matches df, add the info from add_cols entries\n",
    "\n",
    "    matches: pandas DataFrame, library matching result of 1 query on library\n",
    "    documents_library: list of SpectrumDocuments, spectra in library\n",
    "    df: pandas DataFrame, library matching result of 1 query on library with added info\n",
    "    '''\n",
    "    df = matches.copy()\n",
    "    library_ids = df.index.values\n",
    "    if add_cols:\n",
    "        for col in add_cols:\n",
    "            col_data = []\n",
    "            for lib_id in library_ids:\n",
    "                lib_data = documents_library[lib_id]._obj.get(col)\n",
    "                col_data.append(lib_data)\n",
    "            df[col] = col_data\n",
    "    return df\n",
    "\n",
    "def find_tanimoto_sim(matches, documents_library, query_smiles):\n",
    "    '''To each match in matches df, add the tanimoto similarity between query and match\n",
    "\n",
    "    matches: pandas DataFrame, library matching result of 1 query on library\n",
    "    documents_library: list of SpectrumDocuments, spectra in library\n",
    "    df: pandas DataFrame, library matching result of 1 query on library with tanimoto similarities\n",
    "    '''\n",
    "    df = matches.copy()\n",
    "    sims = []\n",
    "    library_ids = df.index.values\n",
    "    \n",
    "    if not query_smiles or query_smiles == \"None\": # check that query smiles exist\n",
    "        df['similarity'] = [0] * len(library_ids) #default to all 0 if it doesnt exist\n",
    "        return df\n",
    "    ms_q = Chem.MolFromSmiles(query_smiles)\n",
    "    if not ms_q: #in case something is wrong with smiles\n",
    "        df['similarity'] = [0] * len(library_ids) #default to all 0 if it doesnt exist\n",
    "        return df\n",
    "    \n",
    "    fp_q = Chem.RDKFingerprint(ms_q)\n",
    "    for lib_id in library_ids:\n",
    "        smiles_lib = documents_library[lib_id]._obj.get(\"smiles\")\n",
    "        if smiles_lib and smiles_lib != \"None\":\n",
    "            ms_lib = Chem.MolFromSmiles(smiles_lib)\n",
    "            if ms_lib:\n",
    "                fp_lib = Chem.RDKFingerprint(ms_lib)\n",
    "                score = DataStructs.FingerprintSimilarity(fp_q, fp_lib)\n",
    "            else: #in case something is wrong with smiles\n",
    "                score = 0\n",
    "        else: #in case it doesnt have smiles\n",
    "            score = 0\n",
    "        sims.append(score)\n",
    "    df['similarity'] = sims\n",
    "    return df\n",
    "\n",
    "def transform_num_matches(input_df, exp = 0.93):\n",
    "    '''Transform the cosine_matches and mod_cosine_matches to between 0-1\n",
    "    \n",
    "    input_df: pandas DataFrame, spec2vec matches for one query\n",
    "    exp: int, the base for the exponential, default: 0.93\n",
    "    \n",
    "    Both matches are transformed to between 0-1 by doing 1-0.93^num_matches\n",
    "    '''\n",
    "    df = input_df.copy() #otherwise it edits the df outside the function\n",
    "    df['cosine_matches'] = [(1-0.93**i) for i in df['cosine_matches']]\n",
    "    df['mod_cosine_matches'] = [(1-0.93**i) for i in df['mod_cosine_matches']]\n",
    "    return df\n",
    "\n",
    "def find_mass_similarity(matches, documents_library, query_mass, base_num = 0.8):\n",
    "    '''\n",
    "    To each match in matches df, add a scaled value for how similar the parent_mass is to the query\n",
    "\n",
    "    matches: pandas DataFrame, library matching result of 1 query on library\n",
    "    documents_library: list of SpectrumDocuments, spectra in library\n",
    "    query_mass: float, parent mass of query\n",
    "    base_num: float, the base for the exponent\n",
    "    df: pandas DataFrame, library matching result of 1 query on library with mass sims\n",
    "    \n",
    "    The similarity in dalton is calculated and transformed into a value 0 - 1 by doing\n",
    "    1 - base_num^diff_in_dalton\n",
    "    '''\n",
    "    df = matches.copy()\n",
    "    library_ids = df.index.values\n",
    "    scaled_mass_sims = []\n",
    "    for lib_id in library_ids:\n",
    "        lib_mass = documents_library[lib_id]._obj.get(\"parent_mass\")\n",
    "        mass_diff = abs(lib_mass - query_mass)\n",
    "        scaled_mass_sim = base_num ** mass_diff\n",
    "        scaled_mass_sims.append(scaled_mass_sim)\n",
    "\n",
    "    #add to df\n",
    "    df['mass_sim'] = scaled_mass_sims\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top20\n",
    "old_and_unique_found_matches_s2v_2dec_top20 = []\n",
    "\n",
    "for matches in old_and_unique_found_matches_s2v_2dec:\n",
    "    old_and_unique_found_matches_s2v_2dec_top20.append(\n",
    "    matches.sort_values(\"s2v_score\", ascending=False).iloc[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joris\\Documents\\eScience_data\\data\\nn_prep_training_found_matches_s2v_2dec.pickle\n",
      "Max parent mass: 13418.370894192036\n"
     ]
    }
   ],
   "source": [
    "outfile = os.path.join(path_data, 'nn_prep_training_found_matches_s2v_2dec.pickle')\n",
    "print(outfile)\n",
    "if os.path.exists(outfile):\n",
    "    with open(outfile, 'rb') as inf:\n",
    "        nn_prep_training_found_matches_s2v_2dec = pickle.load(inf)\n",
    "else:\n",
    "    nn_prep_training_found_matches_s2v_2dec = find_info_matches(old_and_unique_found_matches_s2v_2dec_top20,\n",
    "                                                                old_and_unique_documents_library_s2v_2dec,\n",
    "                                                                old_and_unique_documents_query_s2v_2dec,\n",
    "                                                                max_parent_mass=max_parent_mass)\n",
    "    with open(outfile, 'wb') as outf:\n",
    "        pickle.dump(nn_prep_training_found_matches_s2v_2dec, outf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top20\n",
    "new_and_unique2_found_matches_s2v_2dec_top20 = []\n",
    "\n",
    "for matches in new_and_unique2_found_matches_s2v_2dec:\n",
    "    new_and_unique2_found_matches_s2v_2dec_top20.append(\n",
    "    matches.sort_values(\"s2v_score\", ascending=False).iloc[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joris\\Documents\\eScience_data\\data\\nn_prep_testing_found_matches_s2v_2dec.pickle\n",
      "Max parent mass: 13418.370894192036\n"
     ]
    }
   ],
   "source": [
    "outfile = os.path.join(path_data, 'nn_prep_testing_found_matches_s2v_2dec.pickle')\n",
    "print(outfile)\n",
    "if os.path.exists(outfile):\n",
    "    with open(outfile, 'rb') as inf:\n",
    "        nn_prep_testing_found_matches_s2v_2dec = pickle.load(inf)\n",
    "else:\n",
    "    nn_prep_testing_found_matches_s2v_2dec = find_info_matches(new_and_unique2_found_matches_s2v_2dec_top20,\n",
    "                                                                new_and_unique2_documents_library_s2v_2dec,\n",
    "                                                                new_and_unique2_documents_query_s2v_2dec,\n",
    "                                                                max_parent_mass=max_parent_mass)\n",
    "    with open(outfile, 'wb') as outf:\n",
    "        pickle.dump(nn_prep_testing_found_matches_s2v_2dec, outf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cosine_score</th>\n",
       "      <th>cosine_matches</th>\n",
       "      <th>mod_cosine_score</th>\n",
       "      <th>mod_cosine_matches</th>\n",
       "      <th>s2v_score</th>\n",
       "      <th>label</th>\n",
       "      <th>similarity</th>\n",
       "      <th>parent_mass</th>\n",
       "      <th>mass_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22101</th>\n",
       "      <td>0.928457</td>\n",
       "      <td>0.663299</td>\n",
       "      <td>0.928457</td>\n",
       "      <td>0.663299</td>\n",
       "      <td>0.909346</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.034743</td>\n",
       "      <td>0.999777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20538</th>\n",
       "      <td>0.856661</td>\n",
       "      <td>0.549896</td>\n",
       "      <td>0.856661</td>\n",
       "      <td>0.549896</td>\n",
       "      <td>0.859138</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.034743</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22454</th>\n",
       "      <td>0.857507</td>\n",
       "      <td>0.549896</td>\n",
       "      <td>0.857507</td>\n",
       "      <td>0.549896</td>\n",
       "      <td>0.674490</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.034743</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1366</th>\n",
       "      <td>0.389183</td>\n",
       "      <td>0.549896</td>\n",
       "      <td>0.389183</td>\n",
       "      <td>0.549896</td>\n",
       "      <td>0.584506</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.034744</td>\n",
       "      <td>0.999554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>0.336160</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.337487</td>\n",
       "      <td>0.195643</td>\n",
       "      <td>0.303197</td>\n",
       "      <td>0</td>\n",
       "      <td>0.581808</td>\n",
       "      <td>0.037051</td>\n",
       "      <td>0.000997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cosine_score  cosine_matches  mod_cosine_score  mod_cosine_matches  \\\n",
       "22101      0.928457        0.663299          0.928457            0.663299   \n",
       "20538      0.856661        0.549896          0.856661            0.549896   \n",
       "22454      0.857507        0.549896          0.857507            0.549896   \n",
       "1366       0.389183        0.549896          0.389183            0.549896   \n",
       "5998       0.336160        0.070000          0.337487            0.195643   \n",
       "\n",
       "       s2v_score  label  similarity  parent_mass  mass_sim  \n",
       "22101   0.909346      1    1.000000     0.034743  0.999777  \n",
       "20538   0.859138      1    1.000000     0.034743  1.000000  \n",
       "22454   0.674490      1    1.000000     0.034743  1.000000  \n",
       "1366    0.584506      1    1.000000     0.034744  0.999554  \n",
       "5998    0.303197      0    0.581808     0.037051  0.000997  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_prep_testing_found_matches_s2v_2dec[2].iloc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add matches together for each query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add all the found matches together in one big df\n",
    "nn_training_found_matches_s2v_2dec = nn_prep_training_found_matches_s2v_2dec[0].append(\n",
    "    nn_prep_training_found_matches_s2v_2dec[1:])\n",
    "\n",
    "nn_testing_found_matches_s2v_2dec = nn_prep_testing_found_matches_s2v_2dec[0].append(\n",
    "    nn_prep_testing_found_matches_s2v_2dec[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(nn_training_found_matches_s2v_2dec['similarity'],\n",
    "         alpha=0.5, bins = np.arange(0,1,0.05), label = 'training set')\n",
    "plt.hist(nn_testing_found_matches_s2v_2dec['similarity'],\n",
    "         alpha=0.5, bins = np.arange(0,1,0.05), label = 'test set')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'compat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-da012ea04f52>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#nn function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m def train_nn(X_train, y_train, X_test, y_test, layers = [12, 12, 12, 12, 12, 1],\n",
      "\u001b[1;32mc:\\users\\joris\\documents\\miniconda3\\envs\\spec2vec_analysis\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;31m# We still need all the names that are toplevel on tensorflow_core\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_core\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;31m# These should not be visible in the main tf module.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joris\\documents\\miniconda3\\envs\\spec2vec_analysis\\lib\\site-packages\\tensorflow_core\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mautograph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbitwise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joris\\documents\\miniconda3\\envs\\spec2vec_analysis\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mv1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mforward_compatibility_horizon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joris\\documents\\miniconda3\\envs\\spec2vec_analysis\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mautograph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbitwise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joris\\documents\\miniconda3\\envs\\spec2vec_analysis\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\compat\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mv1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mforward_compatibility_horizon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joris\\documents\\miniconda3\\envs\\spec2vec_analysis\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\compat\\v1\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maudio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mautograph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joris\\documents\\miniconda3\\envs\\spec2vec_analysis\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mv1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mforward_compatibility_horizon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joris\\documents\\miniconda3\\envs\\spec2vec_analysis\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mautograph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbitwise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joris\\documents\\miniconda3\\envs\\spec2vec_analysis\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\compat\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mv1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mforward_compatibility_horizon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joris\\documents\\miniconda3\\envs\\spec2vec_analysis\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\compat\\v1\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    665\u001b[0m \u001b[0m_current_module\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 667\u001b[1;33m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_v1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    668\u001b[0m   _current_module.__path__ = (\n\u001b[0;32m    669\u001b[0m       [_module_util.get_parent_dir(estimator)] + _current_module.__path__)\n",
      "\u001b[1;32mc:\\users\\joris\\documents\\miniconda3\\envs\\spec2vec_analysis\\lib\\site-packages\\tensorflow_estimator\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0m_print_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joris\\documents\\miniconda3\\envs\\spec2vec_analysis\\lib\\site-packages\\tensorflow_estimator\\_api\\v1\\estimator\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexperimental\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexport\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joris\\documents\\miniconda3\\envs\\spec2vec_analysis\\lib\\site-packages\\tensorflow_estimator\\_api\\v1\\estimator\\experimental\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanned\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdnn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdnn_logit_fn_builder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanned\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkmeans\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKMeansClustering\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanned\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLinearSDCA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joris\\documents\\miniconda3\\envs\\spec2vec_analysis\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\dnn.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlosses_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_export\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mestimator_export\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanned\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhead\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mhead_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanned\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joris\\documents\\miniconda3\\envs\\spec2vec_analysis\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodel_fn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmodel_fn_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrun_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutil\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mestimator_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexport_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode_keys\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joris\\documents\\miniconda3\\envs\\spec2vec_analysis\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\util.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0m_DatasetInitializerHook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSessionRunHook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m   \u001b[1;34m\"\"\"Creates a SessionRunHook that initializes the passed iterator.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'compat'"
     ]
    }
   ],
   "source": [
    "#nn function\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "def train_nn(X_train, y_train, X_test, y_test, layers = [12, 12, 12, 12, 12, 1],\n",
    "             model_loss = 'binary_crossentropy', activations = 'relu',\n",
    "             last_activation = 'sigmoid', model_epochs = 20, model_batch_size = 16,\n",
    "             save_name = False):\n",
    "    '''Train a keras deep NN and test on test data, returns (model, history, accuracy, loss)\n",
    "    \n",
    "    X_train: matrix like object like pd.DataFrame, training set\n",
    "    y_train: list like object like np.array, training labels\n",
    "    X_test: matrix like object like pd.DataFrame, test set\n",
    "    y_test: list like object like np.array, test labels\n",
    "    layers: list of ints, the number of layers is the len of this list while the elements\n",
    "        are the amount of neurons per layer, default: [12, 12, 12, 12, 12, 1]\n",
    "    model_loss: str, loss function, default: binary_crossentropy\n",
    "    activations: str, the activation of the layers except the last one, default: relu\n",
    "    last_activation: str, activation of last layer, default: sigmoid\n",
    "    model_epochs: int, number of epochs, default: 20\n",
    "    model_batch_size: int, batch size for updating the model, default: 16\n",
    "    save_name: str, location for saving model, optional, default: False\n",
    "    \n",
    "    Returns:\n",
    "    model: keras sequential\n",
    "    history: dict, training statistics\n",
    "    accuracy: float, accuracy on test set\n",
    "    loss, float, loss on test set\n",
    "    \n",
    "    If save_name is not False and save_name exists this function will load existing model\n",
    "    '''\n",
    "    if os.path.exists(save_name) and save_name:\n",
    "        print('\\nLoading existing model')\n",
    "        nn_model = load_model(save_name)\n",
    "        with open(save_name + '_train_hist.pickle', 'rb') as hist_inf:\n",
    "            history = pickle.load(hist_inf)\n",
    "    else:\n",
    "        # define the keras model\n",
    "        nn_model = Sequential()\n",
    "        #add first layer\n",
    "        nn_model.add(Dense(layers[0], input_dim = X_train.shape[1], activation = activations))\n",
    "        #add other layers\n",
    "        for i in range(1,len(layers)-1): #skip first and last one\n",
    "            nn_model.add(Dense(layers[i], activation = activations))\n",
    "        #add last layer\n",
    "        nn_model.add(Dense(layers[-1], activation = last_activation))\n",
    "        # compile the keras model\n",
    "        nn_model.compile(loss = model_loss, optimizer='adam', metrics=['accuracy'])\n",
    "        # fit the keras model on the dataset\n",
    "        hist = nn_model.fit(X_train, y_train, epochs = model_epochs, batch_size = model_batch_size)\n",
    "        history = hist.history\n",
    "    \n",
    "    #training set\n",
    "    print('Training loss: {:.4f}\\n'.format(history['loss'][-1]))\n",
    "    \n",
    "    #test set    \n",
    "    loss, accuracy = nn_model.evaluate(X_test, y_test)\n",
    "    print('Test accuracy: {:.2f}'.format(accuracy*100))\n",
    "    print('Test loss: {:.4f}'.format(loss))\n",
    "    \n",
    "    if save_name and not os.path.exists(save_name):\n",
    "        print('Saving model at:', save_name)\n",
    "        nn_model.save(save_name)\n",
    "        with open(save_name + '_train_hist.pickle', 'wb') as hist_outf:\n",
    "            pickle.dump(history, hist_outf)\n",
    "    \n",
    "    return nn_model, history, accuracy, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_layers = [10,24,1]\n",
    "#model_name = os.path.join(path_data, 'nn_2000_queries_top20_1')\n",
    "model_name = os.path.join(path_data, 'nn_2000_queries_top20_layers_opt_1') #this one tested best in notebook 3\n",
    "X_tanimoto_top20 = nn_training_old_and_unique_found_matches_s2v.drop(['similarity'], axis = 1)\n",
    "y_tanimoto_top20 = nn_training_old_and_unique_found_matches_s2v['similarity']\n",
    "X_tanimoto_top20_test = nn_testing_new_and_unique2_found_matches_s2v.drop(['similarity'], axis = 1)\n",
    "y_tanimoto_top20_test = nn_testing_new_and_unique2_found_matches_s2v['similarity']\n",
    "\n",
    "nn_2000_queries_top20_1 = train_nn(X_tanimoto_top20, y_tanimoto_top20, X_tanimoto_top20_test, y_tanimoto_top20_test, layers = test_layers,\n",
    "         model_loss = 'mean_squared_error', activations = 'relu', last_activation = None,\n",
    "         model_epochs = 50, model_batch_size = 16, save_name = model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
